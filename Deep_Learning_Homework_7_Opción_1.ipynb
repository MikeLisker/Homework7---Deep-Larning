{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Traducto Ingles a Español\n",
        "#Alejandro Pardo/Michael lisker\n",
        "#INSTALACIONES NECESARIAS\n",
        "\n",
        "!pip install kagglehub --quiet\n",
        "\n",
        "# IMPORTACIONES\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization, MultiHeadAttention, Dense, LayerNormalization\n"
      ],
      "metadata": {
        "id": "8s7dRMWmUsb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DESCARGA DEL DATASET DESDE KAGGLEHUB\n",
        "path = kagglehub.dataset_download(\"tejasurya/eng-spanish\")\n",
        "print(\"Archivos disponibles:\", os.listdir(path))\n",
        "\n",
        "# LECTURA DEL ARCHIVO .txt\n",
        "archivo = os.path.join(path, \"spa.txt\")\n",
        "with open(archivo, encoding=\"utf-8\") as f:\n",
        "    ejemplos = f.read().split(\"\\n\")\n",
        "\n",
        "# PROCESAMIENTO DEL DATASET\n",
        "dataset = []\n",
        "for linea in ejemplos:\n",
        "    partes = linea.split(\"\\t\")\n",
        "    if len(partes) >= 2:\n",
        "        ingles = partes[0]\n",
        "        espanol = \"[start] \" + partes[1] + \" [end]\"\n",
        "        dataset.append((ingles, espanol))\n",
        "\n",
        "# DIVISIÓN DEL DATASET\n",
        "random.shuffle(dataset)\n",
        "val_split = int(0.15 * len(dataset))\n",
        "train_pairs = dataset[:-2 * val_split]\n",
        "val_pairs = dataset[-2 * val_split:-val_split]\n",
        "test_pairs = dataset[-val_split:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvm1F6VvUxpY",
        "outputId": "627633bb-cabe-4a67-d6af-eaf615b57fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tejasurya/eng-spanish?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.3M/10.3M [00:00<00:00, 12.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos disponibles: ['spa.txt', 'spa-eng']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Descarga del dataset: Usamos KaggleHub para descargar el dataset de traducción entre inglés y español.\n",
        "\n",
        "Lectura del archivo: Se lee el archivo spa.txt que contiene las frases de inglés y sus respectivas traducciones al español.\n",
        "\n",
        "Procesamiento de datos: El archivo es procesado línea por línea, y las frases en inglés y español se separan. Las traducciones al español se marcan con los tokens [start] al principio y [end] al final, lo cual es útil para marcar los límites de las traducciones en el modelo.\n",
        "\n",
        "División del dataset: El dataset se divide en tres partes:\n",
        "\n",
        "Entrenamiento (train): 70% de los datos.\n",
        "\n",
        "Validación (val): 15% de los datos.\n",
        "\n",
        "Prueba (test): 15% de los datos.\n",
        "\n",
        "Se utiliza random.shuffle para aleatorizar el dataset antes de la división."
      ],
      "metadata": {
        "id": "yBTvHOhJf5Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIMPIEZA Y VECTORIZACIÓN\n",
        "caracteres_a_eliminar = string.punctuation + \"¿\"\n",
        "caracteres_a_eliminar = caracteres_a_eliminar.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "\n",
        "def estandarizacion(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, f\"[{re.escape(caracteres_a_eliminar)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "vectorizacion_entrada = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "vectorizacion_salida = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=estandarizacion,\n",
        ")\n",
        "\n",
        "# DATOS DE TEXTO\n",
        "train_entrada_texts = [pair[0] for pair in train_pairs]\n",
        "train_salida_texts = [pair[1] for pair in train_pairs]\n",
        "val_entrada_texts = [pair[0] for pair in val_pairs]\n",
        "val_salida_texts = [pair[1] for pair in val_pairs]\n",
        "\n",
        "# ADAPTACIÓN DE VECTORIZADORES\n",
        "vectorizacion_entrada.adapt(train_entrada_texts)\n",
        "vectorizacion_salida.adapt(train_salida_texts)\n"
      ],
      "metadata": {
        "id": "B7yD-cAgU5lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Limpieza de datos: La función estandarizacion elimina los caracteres no deseados (como puntuaciones y caracteres especiales) y convierte el texto a minúsculas. Esto facilita la tokenización y reduce la complejidad del texto.\n",
        "\n",
        "Vectorización:\n",
        "\n",
        "Se utiliza TextVectorization para convertir las frases en secuencias de enteros (tokens).\n",
        "\n",
        "vocab_size define el tamaño del vocabulario, limitando a las 15,000 palabras más frecuentes.\n",
        "\n",
        "sequence_length define la longitud máxima de las secuencias de entrada y salida. Si una secuencia es más larga, se truncará, y si es más corta, se rellenará.\n",
        "\n",
        "vectorizacion_entrada se usa para transformar las frases en inglés, mientras que vectorizacion_salida se usa para las traducciones al español, agregando la funcionalidad de start y end tokens."
      ],
      "metadata": {
        "id": "t0LbvgoMf6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCIONES PARA FORMATEAR LOS DATOS\n",
        "def formato(inputs, targets):\n",
        "    entrada = vectorizacion_entrada(inputs)\n",
        "    salida = vectorizacion_salida(targets)\n",
        "    return {\"entrada\": entrada, \"salida\": salida[:, :-1]}, salida[:, 1:]\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_entrada_texts, train_salida_texts))\n",
        "train_ds = train_ds.batch(batch_size).map(formato).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_entrada_texts, val_salida_texts))\n",
        "val_ds = val_ds.batch(batch_size).map(formato).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# POSICIONAL EMBEDDING\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "3thCZ1qVU99Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Positional Embedding: Esta capa agrega información de la posición de las palabras en la secuencia. Los Transformers no tienen una estructura secuencial explícita, por lo que necesitamos agregar información de la posición de cada palabra en la secuencia para que el modelo pueda entender el orden.\n",
        "\n",
        "token_embeddings: Convierte los tokens (palabras) en vectores de alta dimensión.\n",
        "\n",
        "position_embeddings: Asocia a cada posición de la secuencia un embedding.\n",
        "\n",
        "Finalmente, se suma embedded_tokens y embedded_positions para obtener la representación final de la secuencia."
      ],
      "metadata": {
        "id": "jOeUmYXOgBx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODER\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential([\n",
        "            Dense(dense_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = LayerNormalization()\n",
        "        self.layernorm_2 = LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "0WuXHVKxVAjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Encoder Transformer: El encoder toma la secuencia de entrada (en inglés) y la convierte en una representación de alta dimensión.\n",
        "\n",
        "MultiHeadAttention: Aplica atención de múltiples cabezas para capturar relaciones entre palabras en diferentes posiciones.\n",
        "\n",
        "LayerNormalization: Normaliza las capas para estabilizar el entrenamiento y acelerar la convergencia.\n",
        "\n",
        "Proyecto Denso: Después de la atención, se pasa por una capa densa para aumentar la capacidad de representación del modelo."
      ],
      "metadata": {
        "id": "wMxwQlcJgGJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DECODER\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention_1 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential([\n",
        "            Dense(dense_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = LayerNormalization()\n",
        "        self.layernorm_2 = LayerNormalization()\n",
        "        self.layernorm_3 = LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(seq_length)[:, tf.newaxis]\n",
        "        j = tf.range(seq_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, seq_length, seq_length))\n",
        "        mult = tf.concat([[batch_size], [1], [1]], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "\n",
        "        attention_output_1 = self.attention_1(inputs, inputs, inputs, attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(attention_output_1, encoder_outputs, encoder_outputs, attention_mask=padding_mask)\n",
        "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n"
      ],
      "metadata": {
        "id": "HHlN1SgSVD43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Decoder Transformer: El decoder genera la secuencia de salida (en español) a partir de la representación del encoder.\n",
        "\n",
        "Utiliza atención similar al encoder, pero también aplica más de una capa de atención para procesar la secuencia generada.\n",
        "\n",
        "Causal Attention Mask: Asegura que durante la generación, el modelo no vea futuras palabras en la secuencia."
      ],
      "metadata": {
        "id": "DDLsy6VFgOov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTRUCCIÓN DEL MODELO TRANSFORMER\n",
        "embed_dim = 128\n",
        "dense_dim = 512\n",
        "num_heads = 4\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"entrada\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"salida\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "metadata": {
        "id": "PyFI89KBVGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Definición de la arquitectura completa: Aquí se está construyendo el modelo Transformer.\n",
        "\n",
        "embed_dim, dense_dim, num_heads: Se definen los parámetros clave de la arquitectura, como la dimensión de los embeddings, el tamaño de las capas densas y el número de cabezas de la atención.\n",
        "\n",
        "Encoder: La entrada (en inglés) se pasa a través de un PositionalEmbedding y luego se procesa por el TransformerEncoder.\n",
        "\n",
        "Decoder: La entrada del decoder (en español) también pasa por un PositionalEmbedding y luego por el TransformerDecoder.\n",
        "\n",
        "Dropout: Se utiliza Dropout para prevenir el sobreajuste durante el entrenamiento.\n",
        "\n",
        "Dense: Finalmente, una capa densa se aplica para obtener la salida, que es una distribución de probabilidad sobre el vocabulario en español, utilizando softmax para obtener las probabilidades de cada palabra en la secuencia de salida."
      ],
      "metadata": {
        "id": "qJiDqCAnifzH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uncT4-CjCYjE",
        "outputId": "2e7b4fb4-ad30-49d1-c431-c775425c2f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 63ms/step - accuracy: 0.6973 - loss: 2.8979 - val_accuracy: 0.7639 - val_loss: 1.4977\n",
            "Epoch 2/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7801 - loss: 1.4268 - val_accuracy: 0.8169 - val_loss: 1.1153\n",
            "Epoch 3/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8276 - loss: 1.0883 - val_accuracy: 0.8482 - val_loss: 0.9088\n",
            "Epoch 4/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8502 - loss: 0.9214 - val_accuracy: 0.8540 - val_loss: 0.8547\n",
            "Epoch 5/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8626 - loss: 0.8251 - val_accuracy: 0.8658 - val_loss: 0.7787\n",
            "Epoch 6/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8715 - loss: 0.7590 - val_accuracy: 0.8691 - val_loss: 0.7564\n",
            "Epoch 7/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.8777 - loss: 0.7131 - val_accuracy: 0.8753 - val_loss: 0.7224\n",
            "Epoch 8/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8832 - loss: 0.6765 - val_accuracy: 0.8760 - val_loss: 0.7197\n",
            "Epoch 9/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8873 - loss: 0.6511 - val_accuracy: 0.8725 - val_loss: 0.7340\n",
            "Epoch 10/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8904 - loss: 0.6302 - val_accuracy: 0.8777 - val_loss: 0.7159\n",
            "Epoch 11/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8930 - loss: 0.6147 - val_accuracy: 0.8791 - val_loss: 0.7111\n",
            "Epoch 12/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8954 - loss: 0.6021 - val_accuracy: 0.8782 - val_loss: 0.7189\n",
            "Epoch 13/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8972 - loss: 0.5910 - val_accuracy: 0.8804 - val_loss: 0.7117\n",
            "Epoch 14/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.8989 - loss: 0.5811 - val_accuracy: 0.8802 - val_loss: 0.7131\n",
            "Epoch 15/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9007 - loss: 0.5730 - val_accuracy: 0.8802 - val_loss: 0.7195\n",
            "Epoch 16/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.9017 - loss: 0.5677 - val_accuracy: 0.8825 - val_loss: 0.7187\n",
            "Epoch 17/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9031 - loss: 0.5613 - val_accuracy: 0.8819 - val_loss: 0.7216\n",
            "Epoch 18/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9044 - loss: 0.5561 - val_accuracy: 0.8822 - val_loss: 0.7242\n",
            "Epoch 19/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9054 - loss: 0.5510 - val_accuracy: 0.8807 - val_loss: 0.7410\n",
            "Epoch 20/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9062 - loss: 0.5469 - val_accuracy: 0.8815 - val_loss: 0.7354\n",
            "Epoch 21/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9074 - loss: 0.5422 - val_accuracy: 0.8811 - val_loss: 0.7517\n",
            "Epoch 22/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.9084 - loss: 0.5381 - val_accuracy: 0.8811 - val_loss: 0.7532\n",
            "Epoch 23/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9087 - loss: 0.5350 - val_accuracy: 0.8808 - val_loss: 0.7491\n",
            "Epoch 24/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9098 - loss: 0.5315 - val_accuracy: 0.8812 - val_loss: 0.7578\n",
            "Epoch 25/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9104 - loss: 0.5286 - val_accuracy: 0.8811 - val_loss: 0.7629\n",
            "Epoch 26/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.9111 - loss: 0.5251 - val_accuracy: 0.8785 - val_loss: 0.7764\n",
            "Epoch 27/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9119 - loss: 0.5213 - val_accuracy: 0.8815 - val_loss: 0.7638\n",
            "Epoch 28/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9123 - loss: 0.5198 - val_accuracy: 0.8796 - val_loss: 0.7854\n",
            "Epoch 29/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9130 - loss: 0.5176 - val_accuracy: 0.8820 - val_loss: 0.7727\n",
            "Epoch 30/30\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.9138 - loss: 0.5138 - val_accuracy: 0.8800 - val_loss: 0.7870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ddb442cc550>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# COMPILACIÓN Y ENTRENAMIENTO\n",
        "transformer.compile(optimizer=\"rmsprop\",\n",
        "                    loss=\"sparse_categorical_crossentropy\",\n",
        "                    metrics=[\"accuracy\"])  # Solo se usa 'accuracy'\n",
        "\n",
        "transformer.fit(train_ds,\n",
        "                epochs=30,\n",
        "                validation_data=val_ds,\n",
        "                validation_freq=1)  # La precisión de validación se mostrará automáticamente\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Compilación del modelo:\n",
        "\n",
        "El modelo se compila utilizando rmsprop como optimizador. RMSprop es comúnmente usado para redes neuronales profundas porque es adecuado para el entrenamiento con gradientes estocásticos.\n",
        "\n",
        "Se utiliza sparse_categorical_crossentropy como la función de pérdida. Esto es adecuado para tareas de clasificación multiclase, como la traducción automática, donde cada palabra generada es tratada como una clase.\n",
        "\n",
        "accuracy se usa como la métrica de evaluación, ya que estamos interesados en la precisión de la predicción de palabras.\n",
        "\n",
        "Entrenamiento:\n",
        "\n",
        "El modelo se entrena durante 30 épocas (ajustables según el rendimiento). Durante cada época, se calcula la pérdida y la precisión.\n",
        "\n",
        "Se usa el dataset de entrenamiento (train_ds) y se valida el modelo con val_ds. La precisión de validación se muestra automáticamente al final de cada época."
      ],
      "metadata": {
        "id": "T1oEUXhtih4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA PARA TRADUCIR UNA PALABRA INGRESADA\n",
        "\n",
        "# Función para traducir una palabra en inglés al español\n",
        "def traducir_palabra(entrada_texto):\n",
        "    # Preprocesar la entrada (vectorizarla)\n",
        "    entrada_vectorizada = vectorizacion_entrada([entrada_texto])\n",
        "\n",
        "    # Iniciar la secuencia de salida con el token [start]\n",
        "    decoder_input = tf.constant([[vectorizacion_salida.vocabulary_size() - 2]])  # [start] token\n",
        "\n",
        "    # Generar la traducción palabra por palabra\n",
        "    traduccion = []\n",
        "    for _ in range(sequence_length):  # Limitar la longitud de la traducción\n",
        "        # Hacer la predicción\n",
        "        prediccion = transformer.predict([entrada_vectorizada, decoder_input])\n",
        "\n",
        "        # Obtener la siguiente palabra (con el índice con mayor probabilidad)\n",
        "        prediccion_idx = tf.argmax(prediccion[0], axis=-1)[-1].numpy()\n",
        "\n",
        "        # Convertir el índice en palabra\n",
        "        palabra_predicha = vectorizacion_salida.get_vocabulary()[prediccion_idx]\n",
        "\n",
        "        # Si la predicción es el token [end], terminamos\n",
        "        if palabra_predicha == \"[end]\":\n",
        "            break\n",
        "\n",
        "        # Añadir la palabra predicha a la traducción\n",
        "        traduccion.append(palabra_predicha)\n",
        "\n",
        "        # Actualizar la entrada del decoder con la palabra predicha\n",
        "        decoder_input = tf.concat([decoder_input, tf.constant([[prediccion_idx]])], axis=-1)\n",
        "\n",
        "    # Unir las palabras en una cadena\n",
        "    return \" \".join(traduccion)\n",
        "\n",
        "# Interfaz de entrada de la palabra a traducir\n",
        "entrada_usuario = input(\"Introduce una palabra o frase en inglés para traducir: \")\n",
        "\n",
        "# Traducir y mostrar la traducción\n",
        "traduccion = traducir_palabra(entrada_usuario)\n",
        "print(f\"Traducción al español: {traduccion}\")\n"
      ],
      "metadata": {
        "id": "cpLvBbVYKwvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957647fb-ad4b-47b0-f213-d21c360ef068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduce una palabra o frase en inglés para traducir: i have a great idea and i am a big genious\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Traducción al español: tengo una gran idea y yo soy muy muy bien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Función de traducción:\n",
        "\n",
        "La función traducir_palabra toma como entrada una frase en inglés y genera la traducción correspondiente en español.\n",
        "\n",
        "La entrada se vectoriza usando el vectorizador entrenado para las entradas (inglés).\n",
        "\n",
        "Se inicia la traducción con el token [start], y luego el modelo genera la siguiente palabra en español, una por una, utilizando el decoder.\n",
        "\n",
        "Si el modelo predice el token [end], la traducción se detiene.\n",
        "\n",
        "La predicción se hace palabra por palabra, actualizando el decoder_input con cada nueva palabra generada.\n",
        "\n",
        "Interfaz de usuario: Se le solicita al usuario que ingrese una frase en inglés, y la función devuelve la traducción al español."
      ],
      "metadata": {
        "id": "okBv2J03imkW"
      }
    }
  ]
}